{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a94164-4622-4877-89d1-e565d519004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetson_inference import detectNet\n",
    "from jetson_utils import videoSource, videoOutput, logUsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8248d8a-dffe-4d3b-aee3-20ad3d99cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.add_argument(\"input_URI\", type=str, default=\"\", nargs='?', help=\"URI of the input stream\")\n",
    "# parser.add_argument(\"output_URI\", type=str, default=\"\", nargs='?', help=\"URI of the output stream\")\n",
    "# parser.add_argument(\"--network\", type=str, default=\"ssd-mobilenet-v2\", help=\"pre-trained model to load (see below for options)\")\n",
    "# parser.add_argument(\"--overlay\", type=str, default=\"box,labels,conf\", help=\"detection overlay flags (e.g. --overlay=box,labels,conf)\\nvalid combinations are:  'box', 'labels', 'conf', 'none'\")\n",
    "# parser.add_argument(\"--threshold\", type=float, default=0.5, help=\"minimum detection threshold to use\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b76d804-9112-41fc-8f08-7e82e1aa7f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "jetson.utils -- failed to create videoSource device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m output_URI\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrtp://192.168.3.198:1234\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# create video sources and outputs\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mvideoSource\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m output \u001b[38;5;241m=\u001b[39m videoOutput(output_URI, argv\u001b[38;5;241m=\u001b[39margv\u001b[38;5;241m+\u001b[39mis_headless)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# load the object detection network\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: jetson.utils -- failed to create videoSource device"
     ]
    }
   ],
   "source": [
    "network=\"ssd-mobilenet-v2\"\n",
    "argv=[]\n",
    "threshold=0.5\n",
    "is_headless = [\"--headless\"]\n",
    "overlay=\"box,labels,conf\"\n",
    "\n",
    "input_URI='rtsp://192.168.110.224:8554/unicast'\n",
    "output_URI='rtp://192.168.3.198:1234'\n",
    "input_URI='rtsp://admin:admin@192.168.3.57:8554/live'\n",
    "output_URI='rtp://192.168.3.198:1234'\n",
    "\n",
    "# create video sources and outputs\n",
    "input = videoSource(input_URI, argv=argv)\n",
    "output = videoOutput(output_URI, argv=argv+is_headless)\n",
    "\t\n",
    "# load the object detection network\n",
    "net = detectNet(network, argv, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a6be7-abfb-4fcc-8e94-0172c426a8c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note: to hard-code the paths to load a model, the following API can be used:\n",
    "#\n",
    "# net = detectNet(model=\"model/ssd-mobilenet.onnx\", labels=\"model/labels.txt\", \n",
    "#                 input_blob=\"input_0\", output_cvg=\"scores\", output_bbox=\"boxes\", \n",
    "#                 threshold=args.threshold)\n",
    "\n",
    "# process frames until the user exits\n",
    "while True:\n",
    "\t# capture the next image\n",
    "\timg = input.Capture()\n",
    "\n",
    "\t# detect objects in the image (with overlay)\n",
    "\tdetections = net.Detect(img, overlay=overlay)\n",
    "\n",
    "\t# print the detections\n",
    "\t#print(\"detected {:d} objects in image\".format(len(detections)))\n",
    "\n",
    "\t#for detection in detections:\n",
    "\t\t#print(detection)\n",
    "\n",
    "\t# render the image\n",
    "\toutput.Render(img)\n",
    "\n",
    "\t# update the title bar\n",
    "\toutput.SetStatus(\"{:s} | Network {:.0f} FPS\".format(network, net.GetNetworkFPS()))\n",
    "\n",
    "\t# print out performance info\n",
    "\t#net.PrintProfilerTimes()\n",
    "\n",
    "\t# exit on input/output EOS\n",
    "\tif not input.IsStreaming() or not output.IsStreaming():\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f80781-ce8c-4ba4-b0b3-eeabc2e3a216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
